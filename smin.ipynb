{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import collections\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**this script is used to calculate ic of each term of human datasets, and the mouse dataset is the same**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ontology(object):\n",
    "\n",
    "    def __init__(self, filename='go.obo', with_rels=False):\n",
    "        self.ont = self.load(filename, with_rels)\n",
    "        self.ic = None\n",
    "\n",
    "    def has_term(self, term_id):\n",
    "        return term_id in self.ont\n",
    "\n",
    "    def calculate_ic(self, annots):\n",
    "        cnt = collections.Counter(annots)\n",
    "#         for x in annots:\n",
    "#             cnt.add(x)\n",
    "        self.ic = {}\n",
    "        for go_id, n in cnt.items():\n",
    "            parents = self.get_parents(go_id)\n",
    "            if len(parents) == 0:\n",
    "                min_n = n\n",
    "            else:\n",
    "                min_n = min([cnt[x] for x in parents])\n",
    "            try:\n",
    "                self.ic[go_id] = math.log(max(min_n/n,.00001) / n, 2)\n",
    "            except:\n",
    "                print(min_n,n)\n",
    "    \n",
    "    def get_ic(self, go_id):\n",
    "        if self.ic is None:\n",
    "            raise Exception('Not yet calculated')\n",
    "        if go_id not in self.ic:\n",
    "            return 0.0\n",
    "        return self.ic[go_id]\n",
    "\n",
    "    def load(self, filename, with_rels):\n",
    "        ont = dict()\n",
    "        obj = None\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                if line == '[Term]':\n",
    "                    if obj is not None:\n",
    "                        ont[obj['id']] = obj\n",
    "                    obj = dict()\n",
    "                    obj['is_a'] = list()\n",
    "                    obj['part_of'] = list()\n",
    "                    obj['regulates'] = list()\n",
    "                    obj['alt_ids'] = list()\n",
    "                    obj['is_obsolete'] = False\n",
    "                    continue\n",
    "                elif line == '[Typedef]':\n",
    "                    obj = None\n",
    "                else:\n",
    "                    if obj is None:\n",
    "                        continue\n",
    "                    l = line.split(\": \")\n",
    "                    if l[0] == 'id':\n",
    "                        obj['id'] = l[1]\n",
    "                    elif l[0] == 'alt_id':\n",
    "                        obj['alt_ids'].append(l[1])\n",
    "                    elif l[0] == 'namespace':\n",
    "                        obj['namespace'] = l[1]\n",
    "                    elif l[0] == 'is_a':\n",
    "                        obj['is_a'].append(l[1].split(' ! ')[0])\n",
    "                    elif with_rels and l[0] == 'relationship':\n",
    "                        it = l[1].split()\n",
    "                        # add all types of relationships\n",
    "                        obj['is_a'].append(it[1])\n",
    "                    elif l[0] == 'name':\n",
    "                        obj['name'] = l[1]\n",
    "                    elif l[0] == 'is_obsolete' and l[1] == 'true':\n",
    "                        obj['is_obsolete'] = True\n",
    "        if obj is not None:\n",
    "            ont[obj['id']] = obj\n",
    "        for term_id in list(ont.keys()):\n",
    "            for t_id in ont[term_id]['alt_ids']:\n",
    "                ont[t_id] = ont[term_id]\n",
    "            if ont[term_id]['is_obsolete']:\n",
    "                del ont[term_id]\n",
    "        for term_id, val in ont.items():\n",
    "            if 'children' not in val:\n",
    "                val['children'] = set()\n",
    "            for p_id in val['is_a']:\n",
    "                if p_id in ont:\n",
    "                    if 'children' not in ont[p_id]:\n",
    "                        ont[p_id]['children'] = set()\n",
    "                    ont[p_id]['children'].add(term_id)\n",
    "        return ont\n",
    "\n",
    "\n",
    "    def get_anchestors(self, term_id):\n",
    "        if term_id not in self.ont:\n",
    "            return set()\n",
    "        term_set = set()\n",
    "        q = deque()\n",
    "        q.append(term_id)\n",
    "        while(len(q) > 0):\n",
    "            t_id = q.popleft()\n",
    "            if t_id not in term_set:\n",
    "                term_set.add(t_id)\n",
    "                for parent_id in self.ont[t_id]['is_a']:\n",
    "                    if parent_id in self.ont:\n",
    "                        q.append(parent_id)\n",
    "        return term_set\n",
    "\n",
    "\n",
    "    def get_parents(self, term_id):\n",
    "        if term_id not in self.ont:\n",
    "            return set()\n",
    "        term_set = set()\n",
    "        for parent_id in self.ont[term_id]['is_a']:\n",
    "            if parent_id in self.ont:\n",
    "                term_set.add(parent_id)\n",
    "        return term_set\n",
    "\n",
    "\n",
    "    def get_namespace_terms(self, namespace):\n",
    "        terms = set()\n",
    "        for go_id, obj in self.ont.items():\n",
    "            if obj['namespace'] == namespace:\n",
    "                terms.add(go_id)\n",
    "        return terms\n",
    "\n",
    "    def get_namespace(self, term_id):\n",
    "        return self.ont[term_id]['namespace']\n",
    "    \n",
    "    def get_term_set(self, term_id):\n",
    "        if term_id not in self.ont:\n",
    "            return set()\n",
    "        term_set = set()\n",
    "        q = deque()\n",
    "        q.append(term_id)\n",
    "        while len(q) > 0:\n",
    "            t_id = q.popleft()\n",
    "            if t_id not in term_set:\n",
    "                term_set.add(t_id)\n",
    "                for ch_id in self.ont[t_id]['children']:\n",
    "                    q.append(ch_id)\n",
    "        return term_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "go = Ontology()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**add goterm set extract from the prepare scripts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('uniprot-filtered-organism__Homo+sapiens+(Human)+[9606]_+AND+review--.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = dict(zip(df['Entry'],df['Gene ontology IDs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gos=[]\n",
    "namespace=collections.defaultdict(str)\n",
    "is_a=collections.defaultdict(list)\n",
    "part=collections.defaultdict(list)\n",
    "with open('go.obo','r')as fin:\n",
    "    for line in fin:\n",
    "        if '[Typedef]' in line:\n",
    "            break\n",
    "        if line[:5]=='id: G':\n",
    "            line=line.strip().split()\n",
    "            gos.append(line[1])\n",
    "        elif line[:4]=='is_a':\n",
    "            line=line.strip().split()\n",
    "            is_a[gos[-1]].append(line[1])\n",
    "        elif line[:4]=='rela' and 'part' in line:\n",
    "            line=line.strip().split()\n",
    "            part[gos[-1]].append(line[2])\n",
    "        elif line[:5]=='names':\n",
    "            line=line.strip().split()\n",
    "            namespace[gos[-1]]=line[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in part:\n",
    "    is_a[i].extend(part[i])\n",
    "###true_path_rule\n",
    "def progate(l):\n",
    "    while True:\n",
    "        length=len(l)\n",
    "        temp=[]\n",
    "        for i in l:\n",
    "            temp.extend(is_a[i])\n",
    "        l.update(temp)\n",
    "        if len(l)==length:\n",
    "            return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={}\n",
    "for i in anno:\n",
    "    if not isinstance(anno[i],float):\n",
    "        temp = anno[i].split(';')\n",
    "        for j in range(len(temp)):\n",
    "            temp[j]=temp[j].strip(' ')\n",
    "        labels[i]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in labels:\n",
    "    labels[i]=progate(set(labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "annos_ = []\n",
    "for i in labels:\n",
    "    annos_.extend(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "go.calculate_ic(annos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calculate cco, so as the bpo and mfo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cc_anno.pkl','rb')as f:\n",
    "    cc=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_ic=[]\n",
    "for i in cc:\n",
    "    cc_ic.append(go.get_ic(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cc_ic.pkl','wb')as f:\n",
    "    pickle.dump(cc_ic,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
