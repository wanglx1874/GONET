{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据预处理脚本，把蛋白质序列和ppi分别表示为矩阵和向量，矩阵维度为1500*100，ppi嵌入维度为128**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**基因本体数据按照出现频次划分，每个分支的数据各不相同**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入依赖\n",
    "import pandas as pd\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###trigram vector, 100d\n",
    "pvec={}\n",
    "with open(\"protVec_100d_3grams.csv\",'r')as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split()\n",
    "        line[0] = line[0].strip('\\\"')\n",
    "        line[-1]=line[-1].strip('\\\"')\n",
    "        pvec[line[0]]=list(map(float, line[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 序列数据，转为dataframe\n",
    "df = pd.read_excel('uniprot-filtered-organism__Mus+musculus+(Mouse)+[10090]_+AND+revie-- (1).xlsx')\n",
    "seqs=dict(zip(df['Entry'], df['Sequence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##把序列转为矩阵的函数，这里选择了固定的1500长度，超过的后面部分不计算，不足的padding\n",
    "def seq2vec(seq):\n",
    "    temp=[]\n",
    "    for i in range(1500):\n",
    "        if i>len(seq)-3:\n",
    "            temp.append([0.]*100)\n",
    "        else:\n",
    "            temp.append(pvec.get(seq[i:i+3], [0.]*100))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#此处消耗极大内存 \n",
    "for i in seqs:\n",
    "    seqs[i] = seq2vec(seqs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##标签数据，确保标签和序列大小一致\n",
    "labels=dict(zip(df['Entry'], df['Gene ontology IDs']))\n",
    "len(labels)==len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in labels:\n",
    "    if not isinstance(labels[i],float):\n",
    "        temp = labels[i].split(';')\n",
    "        for j in range(len(temp)):\n",
    "            temp[j]=temp[j].strip(' ')\n",
    "        labels[i]=temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**接下来处理基因本体的数据，按照bpo cco mfo 划分，每个分支各自拥有独立的数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "gos=[]\n",
    "namespace=collections.defaultdict(str)\n",
    "is_a=collections.defaultdict(list)\n",
    "part=collections.defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###根据规则来提取go term ，并依据其之间的依赖关系构建图谱\n",
    "with open('go.obo','r')as fin:\n",
    "    for line in fin:\n",
    "        if '[Typedef]' in line:\n",
    "            break\n",
    "        if line[:5]=='id: G':\n",
    "            line=line.strip().split()\n",
    "            gos.append(line[1])\n",
    "        elif line[:4]=='is_a':\n",
    "            line=line.strip().split()\n",
    "            is_a[gos[-1]].append(line[1])\n",
    "        elif line[:4]=='rela' and 'part' in line:\n",
    "            line=line.strip().split()\n",
    "            part[gos[-1]].append(line[2])\n",
    "        elif line[:5]=='names':\n",
    "            line=line.strip().split()\n",
    "            namespace[gos[-1]]=line[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47432\n",
      "44505\n",
      "8629\n"
     ]
    }
   ],
   "source": [
    "##来看看共有多少个term\n",
    "print(len(gos))\n",
    "print(len(is_a))\n",
    "print(len(part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in part:\n",
    "    is_a[i].extend(part[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###true_path_rule\n",
    "def progate(l):\n",
    "    while True:\n",
    "        length=len(l)\n",
    "        temp=[]\n",
    "        for i in l:\n",
    "            temp.extend(is_a[i])\n",
    "        l.update(temp)\n",
    "        if len(l)==length:\n",
    "            return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##划分子空间，每个子空间是一个集合\n",
    "bp,mf,cc=set(),set(),set()\n",
    "for i in namespace:\n",
    "    if namespace[i]=='biological_process':\n",
    "        bp.add(i)\n",
    "    elif namespace[i]=='molecular_function':\n",
    "        mf.add(i)\n",
    "    elif namespace[i]=='cellular_component':\n",
    "        cc.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17038, 16525)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_with_go={}\n",
    "for i in labels:\n",
    "    if not isinstance(labels[i],float):\n",
    "        labels_with_go[i]=progate(set(labels[i]))\n",
    "len(labels),len(labels_with_go)### some items has no label are discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fre_counter = collections.Counter()\n",
    "for i in labels_with_go:\n",
    "    fre_counter.update(labels_with_go[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_bp,label_cc,label_mf=collections.defaultdict(list),collections.defaultdict(list),\\\n",
    "collections.defaultdict(list)\n",
    "for i in labels_with_go:\n",
    "    \n",
    "    for j in labels_with_go[i]:\n",
    "        if j in bp:\n",
    "            label_bp[i].append(j)\n",
    "        elif j in cc:\n",
    "            label_cc[i].append(j)\n",
    "        elif j in mf:\n",
    "            label_mf[i].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15157\n",
      "15963\n",
      "13733\n"
     ]
    }
   ],
   "source": [
    "print(len(label_bp))\n",
    "print(len(label_cc))\n",
    "print(len(label_mf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_c=collections.Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in label_bp:\n",
    "    #for j in label_bp[i]:\n",
    "    bp_c.update(label_bp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_d=dict(bp_c)\n",
    "bp_set=set()\n",
    "for i in bp_d:\n",
    "    if bp_d[i]>=300:\n",
    "        bp_set.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "683"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##bp 分支共计683个term\n",
    "len(bp_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_label=collections.defaultdict(list)\n",
    "for i in label_bp:\n",
    "    for j in label_bp[i]:\n",
    "        if j in bp_set:\n",
    "            bp_label[i].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15157"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bp_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_c=collections.Counter()\n",
    "for i in label_cc:\n",
    "    #for j in label_bp[i]:\n",
    "    cc_c.update(label_cc[i])\n",
    "cc_d=dict(cc_c)\n",
    "cc_set=set()\n",
    "for i in cc_d:\n",
    "    if cc_d[i]>=100:\n",
    "        cc_set.add(i)\n",
    "cc_label=collections.defaultdict(list)\n",
    "for i in label_cc:\n",
    "    for j in label_cc[i]:\n",
    "        if j in cc_set:\n",
    "            cc_label[i].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cc_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15963"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cc_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_c=collections.Counter()\n",
    "for i in label_mf:\n",
    "    #for j in label_bp[i]:\n",
    "    mf_c.update(label_mf[i])\n",
    "mf_d=dict(mf_c)\n",
    "mf_set=set()\n",
    "for i in mf_d:\n",
    "    if mf_d[i]>=100:\n",
    "        mf_set.add(i)\n",
    "mf_label=collections.defaultdict(list)\n",
    "for i in label_mf:\n",
    "    for j in label_mf[i]:\n",
    "        if j in mf_set:\n",
    "            mf_label[i].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13730"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mf_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mf_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17038"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**下面处理PPI数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##uniprot数据库中有和string数据库对齐的字段\n",
    "mapping=dict(zip(df['Entry'], df['Cross-reference (STRING)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##去掉后面的引号\n",
    "for i in mapping:\n",
    "    if isinstance(mapping[i],str):\n",
    "        mapping[i]=mapping[i].strip(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pevc10090.pkl','rb')as f:\n",
    "    homo=pickle.load(f)\n",
    "names=homo['graph']['id2name']\n",
    "vecs=homo['solver']['vertex_embeddings']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**现在开始对齐数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##构建基因本体term的索引\n",
    "def goterm2idx(term_set):\n",
    "    term_dict=dict(enumerate(term_set))\n",
    "    term_dict={v:k for k,v in term_dict.items()}\n",
    "    return term_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_term2idx=goterm2idx(cc_set)\n",
    "mf_term2idx=goterm2idx(mf_set)\n",
    "bp_term2idx=goterm2idx(bp_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels2onehot(labels,index):\n",
    "    labels_new={}\n",
    "    l=len(index)\n",
    "    for i in labels:\n",
    "        temp = [0]*l\n",
    "        for j in labels[i]:\n",
    "            temp[index[j]]=1\n",
    "        labels_new[i]=temp\n",
    "    return labels_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_label2onehot=labels2onehot(cc_label,cc_term2idx)\n",
    "bp_label2onehot=labels2onehot(bp_label,bp_term2idx)\n",
    "mf_label2onehot=labels2onehot(mf_label,mf_term2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_entry=list(cc_label.keys())\n",
    "bp_entry=list(bp_label.keys())\n",
    "mf_entry=list(mf_label.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_emb=[]\n",
    "bp_ppi=[]\n",
    "bp_la=[]\n",
    "for i in bp_entry:\n",
    "    bp_emb.append(seqs[i])\n",
    "    bp_la.append(bp_label2onehot[i])\n",
    "    m=mapping[i]\n",
    "    if m in names:\n",
    "        bp_ppi.append(vecs[names.index(m)].tolist())\n",
    "    else:\n",
    "        bp_ppi.append([0.]*128)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train=bp_emb[:11000]\n",
    "emb_test=bp_emb[11000:]\n",
    "ppi_vec_train=bp_ppi[:11000]\n",
    "ppi_vec_test=bp_ppi[11000:]\n",
    "labels_train=bp_la[:11000]\n",
    "labels_test=bp_la[11000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10609.9"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bp_entry)*.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bp/emb_train.pkl','wb')as f:\n",
    "    pickle.dump(emb_train,f)\n",
    "with open('bp/emb_test.pkl','wb')as f:\n",
    "    pickle.dump(emb_test,f)\n",
    "with open('bp/ppi_train.pkl','wb')as f:\n",
    "    pickle.dump(ppi_vec_train,f)\n",
    "with open('bp/ppi_test.pkl','wb')as f:\n",
    "    pickle.dump(ppi_vec_test,f)\n",
    "with open('bp/labels_train.pkl','wb')as f:\n",
    "    pickle.dump(labels_train,f)\n",
    "with open('bp/labels_test.pkl','wb')as f:\n",
    "    pickle.dump(labels_test,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_emb=[]\n",
    "mf_ppi=[]\n",
    "mf_la=[]\n",
    "for i in mf_entry:\n",
    "    mf_emb.append(seqs[i])\n",
    "    mf_la.append(mf_label2onehot[i])\n",
    "    m=mapping[i]\n",
    "    if m in names:\n",
    "        mf_ppi.append(vecs[names.index(m)].tolist())\n",
    "    else:\n",
    "        mf_ppi.append([0.]*128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mf_emb)==len(mf_la)==len(mf_ppi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train=mf_emb[:9000]\n",
    "emb_test=mf_emb[9000:]\n",
    "ppi_vec_train=mf_ppi[:9000]\n",
    "ppi_vec_test=mf_ppi[9000:]\n",
    "labels_train=mf_la[:9000]\n",
    "labels_test=mf_la[9000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mf/emb_train.pkl','wb')as f:\n",
    "    pickle.dump(emb_train,f)\n",
    "with open('mf/emb_test.pkl','wb')as f:\n",
    "    pickle.dump(emb_test,f)\n",
    "with open('mf/ppi_train.pkl','wb')as f:\n",
    "    pickle.dump(ppi_vec_train,f)\n",
    "with open('mf/ppi_test.pkl','wb')as f:\n",
    "    pickle.dump(ppi_vec_test,f)\n",
    "with open('mf/labels_train.pkl','wb')as f:\n",
    "    pickle.dump(labels_train,f)\n",
    "with open('mf/labels_test.pkl','wb')as f:\n",
    "    pickle.dump(labels_test,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_emb=[]\n",
    "cc_ppi=[]\n",
    "cc_la=[]\n",
    "for i in cc_entry:\n",
    "    cc_emb.append(seqs[i])\n",
    "    cc_la.append(cc_label2onehot[i])\n",
    "    m=mapping[i]\n",
    "    if m in names:\n",
    "        cc_ppi.append(vecs[names.index(m)].tolist())\n",
    "    else:\n",
    "        cc_ppi.append([0.]*128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train=cc_emb[:12000]\n",
    "emb_test=cc_emb[12000:]\n",
    "ppi_vec_train=cc_ppi[:12000]\n",
    "ppi_vec_test=cc_ppi[12000:]\n",
    "labels_train=cc_la[:12000]\n",
    "labels_test=cc_la[12000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cc/emb_train.pkl','wb')as f:\n",
    "    pickle.dump(emb_train,f)\n",
    "with open('cc/emb_test.pkl','wb')as f:\n",
    "    pickle.dump(emb_test,f)\n",
    "with open('cc/ppi_train.pkl','wb')as f:\n",
    "    pickle.dump(ppi_vec_train,f)\n",
    "with open('cc/ppi_test.pkl','wb')as f:\n",
    "    pickle.dump(ppi_vec_test,f)\n",
    "with open('cc/labels_train.pkl','wb')as f:\n",
    "    pickle.dump(labels_train,f)\n",
    "with open('cc/labels_test.pkl','wb')as f:\n",
    "    pickle.dump(labels_test,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_emb=[]\n",
    "mf_ppi=[]\n",
    "mf_la=[]\n",
    "for i in mf_entry:\n",
    "    mf_emb.append(seqs[i])\n",
    "    mf_la.append(mf_label2onehot[i])\n",
    "    m=mapping[i]\n",
    "    if m in names:\n",
    "        mf_ppi.append(vecs[names.index(m)].tolist())\n",
    "    else:\n",
    "        mf_ppi.append([0.]*128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train=mf_emb[:10000]\n",
    "emb_test=mf_emb[10000:]\n",
    "ppi_vec_train=mf_ppi[:10000]\n",
    "ppi_vec_test=mf_ppi[10000:]\n",
    "labels_train=mf_la[:10000]\n",
    "labels_test=mf_la[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mf/emb_train.pkl','wb')as f:\n",
    "    pickle.dump(emb_train,f)\n",
    "with open('mf/emb_test.pkl','wb')as f:\n",
    "    pickle.dump(emb_test,f)\n",
    "with open('mf/ppi_train.pkl','wb')as f:\n",
    "    pickle.dump(ppi_vec_train,f)\n",
    "with open('mf/ppi_test.pkl','wb')as f:\n",
    "    pickle.dump(ppi_vec_test,f)\n",
    "with open('mf/labels_train.pkl','wb')as f:\n",
    "    pickle.dump(labels_train,f)\n",
    "with open('mf/labels_test.pkl','wb')as f:\n",
    "    pickle.dump(labels_test,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
