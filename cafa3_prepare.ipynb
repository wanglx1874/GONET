{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**这个脚本用来评估cafa3上各个模型的性能**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##同样的 需要使用pvec\n",
    "pvec={}\n",
    "with open('protVec_100d_3grams.csv','r')as fin:\n",
    "    for line in fin:\n",
    "        line=line.strip('\\\"').split()\n",
    "        name=line[0]\n",
    "        line[-1]=line[-1].strip('\\\"')\n",
    "        vec=list(map(float,line[1:]))\n",
    "#         print(name)\n",
    "#         print(vec)\n",
    "        pvec[name]=vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##准备fasta数据\n",
    "k,v=[],[]\n",
    "with open('cafa3/uniprot_sprot_exp.fasta','r')as fin:\n",
    "    for line in fin:\n",
    "        #print(line)\n",
    "        line=line.strip()\n",
    "        if line.startswith('>'):\n",
    "            k.append(line[1:])\n",
    "            v.append('')\n",
    "        else:\n",
    "            v[-1]+=line.strip()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##标签数据\n",
    "labels=collections.defaultdict(list)\n",
    "domains=collections.defaultdict(list)\n",
    "with open('cafa3/uniprot_sprot_exp.txt','r')as fin:\n",
    "    for line in fin:\n",
    "        line=line.split()\n",
    "        domains[line[-1]].append(line[1])\n",
    "        labels[line[0]].append(line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2vec(seq):\n",
    "    temp=[]\n",
    "    for i in range(1500):\n",
    "        if i>len(seq)-3:\n",
    "            temp.append([0.]*100)\n",
    "        else:\n",
    "            temp.append(pvec.get(seq[i:i+3], [0.]*100))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##把序列转为向量\n",
    "for i in range(len(v)):\n",
    "    v[i] = seq2vec(v[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = {}\n",
    "for i in range(len(v)):\n",
    "    seqs[k[i]] = v[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###下面处理标签\n",
    "gos=[]\n",
    "namespace=collections.defaultdict(str)\n",
    "is_a=collections.defaultdict(list)\n",
    "part=collections.defaultdict(list)\n",
    "with open('cafa3/go.obo','r')as fin:\n",
    "    for line in fin:\n",
    "        if '[Typedef]' in line:\n",
    "            break\n",
    "        if line[:5]=='id: G':\n",
    "            line=line.strip().split()\n",
    "            gos.append(line[1])\n",
    "        elif line[:4]=='is_a':\n",
    "            line=line.strip().split()\n",
    "            is_a[gos[-1]].append(line[1])\n",
    "        elif line[:4]=='rela' and 'part' in line:\n",
    "            line=line.strip().split()\n",
    "            part[gos[-1]].append(line[2])\n",
    "        elif line[:5]=='names':\n",
    "            line=line.strip().split()\n",
    "            namespace[gos[-1]]=line[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'biological_process': 30780,\n",
       "         'molecular_function': 12196,\n",
       "         'cellular_component': 4450})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 统计各分支中term的个数\n",
    "c=collections.Counter(namespace.values())\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##去除分支之内的term\n",
    "bp,mf,cc=set(),set(),set()\n",
    "for i in namespace:\n",
    "    if namespace[i]=='biological_process':\n",
    "        bp.add(i)\n",
    "    elif namespace[i]=='molecular_function':\n",
    "        mf.add(i)\n",
    "    elif namespace[i]=='cellular_component':\n",
    "        cc.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in part:\n",
    "    is_a[i].extend(part[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##cafa3的标签比较稀疏，利用True path rule 来补全\n",
    "def progate(l):\n",
    "    while True:\n",
    "        length=len(l)\n",
    "        temp=[]\n",
    "        for i in l:\n",
    "            temp.extend(is_a[i])\n",
    "        l.update(temp)\n",
    "        if len(l)==length:\n",
    "            return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in labels:\n",
    "    if labels[i]:\n",
    "        labels[i]=progate(set(labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fre_counter = collections.Counter()\n",
    "for i in labels:\n",
    "    fre_counter.update(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_set = set()\n",
    "for i in cc:\n",
    "    if fre_counter[i]>100:\n",
    "        cc_set.add(i)  ##381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_set = set()\n",
    "for i in bp:\n",
    "    if fre_counter[i]>400:\n",
    "        bp_set.add(i)   ##len 844"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    }
   ],
   "source": [
    "mf_set = set()\n",
    "for i in mf:\n",
    "    if fre_counter[i]>100:\n",
    "        mf_set.add(i)\n",
    "print(len(mf_set))  ##403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_cc = []  ##49138\n",
    "emb_cc = []\n",
    "entry = []\n",
    "for i in labels:\n",
    "    temp = []\n",
    "    for j in labels[i]:\n",
    "        if j in cc_set:\n",
    "            temp.append(j)\n",
    "    if len(temp)>0:\n",
    "        labels_cc.append(temp)\n",
    "        emb_cc.append(seqs[i])\n",
    "        entry.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_bp = [] ##52191\n",
    "emb_bp = []\n",
    "entry_bp = []\n",
    "for i in labels:\n",
    "    temp = []\n",
    "    for j in labels[i]:\n",
    "        if j in bp_set:\n",
    "            temp.append(j)\n",
    "    if len(temp)>0:\n",
    "        labels_bp.append(temp)\n",
    "        emb_bp.append(seqs[i])\n",
    "        entry_bp.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_mf = []  ###34343\n",
    "emb_mf = []\n",
    "entry_mf = []\n",
    "for i in labels:\n",
    "    temp = []\n",
    "    for j in labels[i]:\n",
    "        if j in mf_set:\n",
    "            temp.append(j)\n",
    "    if len(temp)>0:\n",
    "        labels_mf.append(temp)\n",
    "        emb_mf.append(seqs[i])\n",
    "        entry_mf.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_cc2onehot = []\n",
    "term2idx=dict(enumerate(cc_set))\n",
    "term2idx={v:k for k,v in term2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_bp2onehot = []\n",
    "term2idx_bp=dict(enumerate(bp_set))\n",
    "term2idx_bp={v:k for k,v in term2idx_bp.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_mf2onehot = []\n",
    "term2idx_mf=dict(enumerate(mf_set))\n",
    "term2idx_mf={v:k for k,v in term2idx_mf.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in labels_cc:\n",
    "    temp = [0]*len(cc_set)\n",
    "    for j in i:\n",
    "        temp[term2idx[j]]=1\n",
    "    labels_cc2onehot.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in labels_bp:\n",
    "    temp = [0]*len(bp_set)\n",
    "    for j in i:\n",
    "        temp[term2idx_bp[j]]=1\n",
    "    labels_bp2onehot.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in labels_mf:\n",
    "    temp = [0]*len(mf_set)\n",
    "    for j in i:\n",
    "        temp[term2idx_mf[j]]=1\n",
    "    labels_mf2onehot.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb_mf = emb_mf[:15000]\n",
    "train_label_mf = labels_mf2onehot[:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "###label smoothing\n",
    "train_label_mf_smoothed = []\n",
    "for i in train_label_mf:\n",
    "    c = sum(i)\n",
    "    sm = 0.15*c/len(i)\n",
    "    temp=[]\n",
    "    for  j in i:\n",
    "        if j==0.:\n",
    "            temp.append(sm)\n",
    "        elif j==1.:\n",
    "            temp.append(0.85+sm)\n",
    "    train_label_mf_smoothed.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cafa3/train_emb_mf.pkl','wb')as f:\n",
    "    pickle.dump(train_emb_mf,f)\n",
    "with open('cafa3/label_mf_smoothed.pkl','wb')as f:\n",
    "    pickle.dump(train_label_mf_smoothed,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emb_mf = emb_mf[15000:20000]\n",
    "test_label_mf = labels_mf2onehot[15000:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cafa3/test_emb_mf.pkl','wb')as f:\n",
    "    pickle.dump(test_emb_mf,f)\n",
    "with open('cafa3/test_label_mf.pkl','wb')as f:\n",
    "    pickle.dump(test_label_mf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cafa3/label_mf_unsmoothed.pkl','wb')as f:\n",
    "    pickle.dump(train_label_mf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
